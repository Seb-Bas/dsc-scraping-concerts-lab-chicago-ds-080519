{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Concerts - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen how to scrape a simple website, it's time to again practice those skills on a full-fledged site!\n",
    "In this lab, you'll practice your scraping skills on a music website: https://www.residentadvisor.net.\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Scrape events from a website\n",
    "* Follow links to those events to retrieve further information\n",
    "* Clean and store scraped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Website\n",
    "\n",
    "For this lab, you'll be scraping the https://www.residentadvisor.net website. Start by navigating to the events page [here](https://www.residentadvisor.net/events) in your browser.\n",
    "\n",
    "<img src=\"images/ra.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.findAll('p', class_ = \"eventDate date\")\n",
    "# print([x for x in soup.findAll('h1', class_ = 'event-title')[0].children][0].text)\n",
    "# print('\\n')\n",
    "# print([x for x in soup.findAll('h1', class_ = 'event-title')[0].children][2].contents[3].text)\n",
    "# print('\\n')\n",
    "# print([x for x in soup.findAll('h1', class_ = 'event-title')[0].children][2].contents[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_sib_search(container):\n",
    "    result = [x for x in container.children][0]['class'][0]\n",
    "    count = 0\n",
    "    while result == 'event-item':\n",
    "        count += 1\n",
    "        container = container.next_sibling\n",
    "        try:\n",
    "            result = [x for x in container.children][0]['class'][0]\n",
    "        except:\n",
    "            break\n",
    "    return count\n",
    "\n",
    "\n",
    "def retrieve_dates(soup):\n",
    "    found = soup.findAll('p', class_ = \"eventDate date\")\n",
    "    sibs = [x.parent.next_sibling for x in found]\n",
    "    event_dates = []\n",
    "\n",
    "    for i in range(len(found)):\n",
    "        for number in range(next_sib_search(sibs[i])):\n",
    "            event_dates.append(found[i].text[:-2])\n",
    "    return event_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_names(soup):\n",
    "    found = soup.findAll('h1', class_ = 'event-title')\n",
    "    names = []\n",
    "    for i in range(len(found)):\n",
    "        names.append([x for x in found[i].children][0].text)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_venues(soup):\n",
    "    found = soup.findAll('h1', class_ = 'event-title')\n",
    "    venues = []\n",
    "    for i in range(len(found)):\n",
    "        venues.append([x for x in found[i].children][2].contents[1].text)\n",
    "    return venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_goers(soup):\n",
    "    attendees = [x.contents[0].text for x in soup.findAll('p', class_ = 'attending')]\n",
    "    return attendees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to Scrape all of the Events on the Given Page Events Page\n",
    "\n",
    "The function should return a Pandas DataFrame with columns for the Event_Name, Venue, Event_Date and Number_of_Attendees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_events(url):\n",
    "    html_page = requests.get(url)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    names = retrieve_names(soup)\n",
    "    venues = retrieve_venues(soup)\n",
    "    dates = retrieve_dates(soup)\n",
    "    attendees = retrieve_goers(soup)\n",
    "    data = [names, venues, dates, attendees]\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.T\n",
    "    df.columns = [\"Event_Name\", \"Venue\", \"Event_Date\", \"Number_of_Attendees\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Next 1000 Events for Your Area\n",
    "\n",
    "Display the data sorted by the number of attendees. If there is a tie for the number attending, sort by event date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "def scrape_thousand_events(events_page_url):\n",
    "    from datetime import date\n",
    "    import datetime as dt\n",
    "    day = date.today()\n",
    "    iterator = dt.timedelta(weeks = 1)\n",
    "    url = events_page_url + f'/us/illinois/week/{day}'\n",
    "    dfs = []\n",
    "    df = scrape_events(url)\n",
    "    dfs.append(df)\n",
    "    count = df.shape[0]\n",
    "    while count < 1000:\n",
    "        day += iterator\n",
    "        url = events_page_url + f'/us/illinois/week/{day}'\n",
    "        new_df = scrape_events(url)\n",
    "        count += new_df.shape[0]\n",
    "        if new_df.shape[0] == 0:\n",
    "            break\n",
    "        dfs.append(new_df)\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = scrape_thousand_events(\"https://www.residentadvisor.net/events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_int(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        x = 0\n",
    "    return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['Number_of_Attendees'] = events['Number_of_Attendees'].apply(replace_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['Event_Day'] = events['Event_Date'].str[:3]\n",
    "events['Event_Date'] = events['Event_Date'].str[4:]\n",
    "events['Event_Date'] = pd.to_datetime(events['Event_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events.sort_values(by = ['Number_of_Attendees', 'Event_Date'], ascending = [False, True])\n",
    "events.reset_index(inplace = True).drop(columns = ['index'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_Name</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Number_of_Attendees</th>\n",
       "      <th>Event_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Format x Sleepwalker present: FJAAK</td>\n",
       "      <td>TBA - Chicago</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>103</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spybar &amp; Nightsweat presents: Dax J</td>\n",
       "      <td>Spybar</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>64</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obscure 033: Scuba presents SCB</td>\n",
       "      <td>TBA - Chicago</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>51</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Format and Synthetik Minds present: Perc, Remc...</td>\n",
       "      <td>TBA - Chicago</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>46</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excursions: Underground</td>\n",
       "      <td>The Post</td>\n",
       "      <td>2019-10-05</td>\n",
       "      <td>29</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WYA Chi: Mike Servito (The Bunker NY)</td>\n",
       "      <td>TBA - Chicago</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>29</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Loose Ends with Honey Dijon / Harry Cross</td>\n",
       "      <td>smartbar</td>\n",
       "      <td>2019-10-12</td>\n",
       "      <td>27</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Black Madonna / Peach / Phillip Stone</td>\n",
       "      <td>smartbar</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>21</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Liebing</td>\n",
       "      <td>Spybar</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>20</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ghostly 20 - Metro/smartbar All-Building - fea...</td>\n",
       "      <td>smartbar</td>\n",
       "      <td>2019-10-19</td>\n",
       "      <td>20</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Event_Name          Venue  \\\n",
       "0                Format x Sleepwalker present: FJAAK  TBA - Chicago   \n",
       "1                Spybar & Nightsweat presents: Dax J         Spybar   \n",
       "2                    Obscure 033: Scuba presents SCB  TBA - Chicago   \n",
       "3  Format and Synthetik Minds present: Perc, Remc...  TBA - Chicago   \n",
       "4                            Excursions: Underground       The Post   \n",
       "5              WYA Chi: Mike Servito (The Bunker NY)  TBA - Chicago   \n",
       "6          Loose Ends with Honey Dijon / Harry Cross       smartbar   \n",
       "7          The Black Madonna / Peach / Phillip Stone       smartbar   \n",
       "8                                      Chris Liebing         Spybar   \n",
       "9  Ghostly 20 - Metro/smartbar All-Building - fea...       smartbar   \n",
       "\n",
       "  Event_Date  Number_of_Attendees Event_Day  \n",
       "0 2019-09-06                  103       Fri  \n",
       "1 2019-09-12                   64       Thu  \n",
       "2 2019-09-13                   51       Fri  \n",
       "3 2019-10-11                   46       Fri  \n",
       "4 2019-10-05                   29       Sat  \n",
       "5 2019-10-25                   29       Fri  \n",
       "6 2019-10-12                   27       Sat  \n",
       "7 2019-09-28                   21       Sat  \n",
       "8 2019-09-06                   20       Fri  \n",
       "9 2019-10-19                   20       Sat  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Congratulations! In this lab, you successfully scraped a website for concert event information!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
